{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Computer Vision\n",
        "# Phân loại hình ảnh sử dụng mô hình Bag-of-Words\n",
        "Nguyễn Quốc Thái - 20212642M\n",
        "\n",
        "Chu Văn Tiến - 20212164M"
      ],
      "metadata": {
        "id": "wkEmvWKWT_5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxy3LM3BYb1u",
        "outputId": "93d20899-8f97-4394-f192-8a8d8779ee01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ThaiNQ_WorkSpace/image_classification_bow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEbe63OQYy_E",
        "outputId": "38977eb1-1e09-4716-c1ea-80db5a068db7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ThaiNQ_WorkSpace/image_classification_bow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Chuẩn bị dữ liệu"
      ],
      "metadata": {
        "id": "KLKeIW5eUwjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bộ dữ liệu phân loại hình ảnh chó và mèo gồm 25.000 ảnh"
      ],
      "metadata": {
        "id": "_OvxnVaGUXHe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAx86jSPhql3"
      },
      "outputs": [],
      "source": [
        "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
        "!unzip kagglecatsanddogs_5340.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYRxOqjUaIkQ"
      },
      "source": [
        "Từ 25.000 ảnh, chọn bộ dữ liệu nhỏ chia thành 2 tập:\n",
        "- Tập huấn luyện: 3.000 ảnh thuộc nhãn chó, 3.000 ảnh thuộc nhãn mèo\n",
        "- Tập đánh giá: 1.000 ảnh thuộc nhãn chó, 1.000 ảnh thuộc nhãn mèo\n",
        "\n",
        "Tập dữ liệu 8.000 ảnh có thể download từ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cqV-Qmv97MD"
      },
      "outputs": [],
      "source": [
        "!gdown 1-0dkrkks7AiatR5EQCozdiE2Q9nfSUga\n",
        "!unzip cats_and_dogs.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Đọc dữ liệu từ thư mục"
      ],
      "metadata": {
        "id": "NH4hW5OYVRU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U1xzthKg-RJl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def read_data_from_folder(input_dir, data_type):\n",
        "    image_paths, image_labels = [], []\n",
        "    input_path = os.path.join(input_dir, data_type)\n",
        "    for class_name in os.listdir(input_path):\n",
        "        class_path = os.path.join(input_path, class_name)\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "            if class_name == 'cats':\n",
        "                image_paths.append(image_path)\n",
        "                image_labels.append(0)\n",
        "            elif class_name == 'dogs':\n",
        "                image_paths.append(image_path)\n",
        "                image_labels.append(1)\n",
        "            else:\n",
        "                pass\n",
        "    return image_paths, image_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.Save và load các dữ liệu (các đặc trưng và bộ từ điển trực quan)"
      ],
      "metadata": {
        "id": "816ghDgNVbjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gwsqdQXk-a6E"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def save_data(data, save_file_path):\n",
        "    \"\"\" Save data into save file path \"\"\"\n",
        "    with open(save_file_path, \"wb\") as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "\n",
        "def load_data(save_file_path):\n",
        "    \"\"\"Load data from the save file path\"\"\"\n",
        "    with open(save_file_path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Trích chọn đặc trưng cục bộ sử dụng SIFT và xây dựng bộ từ điển trực quan"
      ],
      "metadata": {
        "id": "vsS1O-Y1VpRF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2Rj4slHI-czX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "class ImageProcesser:\n",
        "    def __init__(self, feature_extractor='sift'):\n",
        "\n",
        "        self.feature_extractor = feature_extractor\n",
        "\n",
        "        if self.feature_extractor.lower() == 'sift':\n",
        "            self.extractor = cv2.xfeatures2d.SIFT_create()\n",
        "\n",
        "        elif self.feature_extractor.lower() == 'kaze':\n",
        "            self.extractor = cv2.KAZE_create()\n",
        "        else:\n",
        "            print('Support two algorithms: sift | kaze')\n",
        "    \n",
        "    def convert_to_gray(self, image):\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        return gray\n",
        "    \n",
        "    def convert_to_feature(self, image):\n",
        "        keypoints, descriptors = self.extractor.detectAndCompute(image, None)\n",
        "        return keypoints, descriptors\n",
        "\n",
        "\n",
        "def extract_feature(image_paths, image_labels, save_feature_path, image_processer):\n",
        "    \"\"\"Extract the feature for all the images in input dir. \"\"\"\n",
        "\n",
        "    features, labels = [], []\n",
        "    # Read images\n",
        "    for image_path, image_label in tqdm(zip(image_paths, image_labels)):\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is not None:\n",
        "            image_gray = image_processer.convert_to_gray(image)\n",
        "            keypoints, descriptors = image_processer.convert_to_feature(image_gray)\n",
        "            if descriptors is not None:\n",
        "                features.append(descriptors)\n",
        "                labels.append(image_label)\n",
        "            \n",
        "    data_images = {\n",
        "        'features': features,\n",
        "        'labels': labels\n",
        "    }\n",
        "    save_data(data_images, save_feature_path)\n",
        "\n",
        "    return features, labels\n",
        "  \n",
        "def build_codebook(save_feature_path, save_codebook_path, vocab_size=400):\n",
        "    \"\"\"Build the codebook (dictionary) for all the images in input dir. \"\"\"\n",
        "\n",
        "    data_image = load_data(save_feature_path)\n",
        "\n",
        "    bow = cv2.BOWKMeansTrainer(vocab_size)\n",
        "    # Read feature\n",
        "    for feature in tqdm(data_image['features']):\n",
        "        bow.add(feature)\n",
        "    # Cluster all the descriptors and save it into output file\n",
        "    codebook = bow.cluster()\n",
        "    # Save code books\n",
        "    save_data(codebook, save_codebook_path)\n",
        "\n",
        "    return codebook"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.Biểu diễn hình ảnh dựa vào bộ từ điển trực quan"
      ],
      "metadata": {
        "id": "rzxWgvj1WGdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eZQAoFfv-e0e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import pickle\n",
        "\n",
        "def get_bow_extractor(image_processer, codebook):\n",
        "    \"\"\"Get the bag of words extractor object.\"\"\"\n",
        "    # Using FLANN matcher to match features\n",
        "    FLANN_INDEX_KDTREE = 0\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "    flann_matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    # Create the bow extractor\n",
        "    bow_extractor = cv2.BOWImgDescriptorExtractor(image_processer.extractor, flann_matcher)\n",
        "    bow_extractor.setVocabulary(codebook)\n",
        "    return bow_extractor\n",
        "\n",
        "def get_histogram(image_processer, bow_extractor, image):\n",
        "    \"\"\"Represent an image as histogram of visual codewords.\n",
        "    \"\"\"\n",
        "    gray = image_processer.convert_to_gray(image)\n",
        "    if gray is not None:\n",
        "        keypoints = image_processer.extractor.detect(gray, None)\n",
        "        histogram = bow_extractor.compute(gray, keypoints)\n",
        "        return histogram\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def get_cat_dog_data(image_processer, save_codebook_path, image_paths, train_image_labels):\n",
        "    \"\"\"Represent cat vs dog images as histogram of visual \"\"\"\n",
        "\n",
        "    codebook = load_data(save_codebook_path)\n",
        "    bow_extractor = get_bow_extractor(image_processer, codebook)\n",
        "\n",
        "    mega_data, mega_label = [], []\n",
        "    for image_path, image_label in tqdm(zip(image_paths, train_image_labels)):\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is not None:\n",
        "            histogram = get_histogram(image_processer, bow_extractor, image)\n",
        "            if histogram is not None:\n",
        "                mega_data.append(histogram)\n",
        "                mega_label.append(image_label)\n",
        "\n",
        "    return mega_data, mega_label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.Huấn luyện và đánh giá mô hình"
      ],
      "metadata": {
        "id": "zT5ZRiJ5Whzb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KkH6zTrJ-hWq"
      },
      "outputs": [],
      "source": [
        "alg_extractor = 'sift'\n",
        "input_dir = 'cats_and_dogs'\n",
        "vocab_size = 200\n",
        "save_feature_path = os.path.join('save_data', f'feature_{alg_extractor}.pkl')\n",
        "save_codebook_path = os.path.join('save_data', f'codebook_{alg_extractor}_{str(vocab_size)}.pkl')\n",
        "\n",
        "image_processer = ImageProcesser(alg_extractor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alg_extractor = 'sift'\n",
        "input_dir = 'cats_and_dogs'\n",
        "vocab_size = 400\n",
        "save_feature_path = os.path.join('save_data', f'feature_{alg_extractor}.pkl')\n",
        "save_codebook_path = os.path.join('save_data', f'codebook_{alg_extractor}_{str(vocab_size)}.pkl')\n",
        "\n",
        "image_processer = ImageProcesser(alg_extractor)"
      ],
      "metadata": {
        "id": "Myu2uEN4Y9dC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xLvvk8EK-myI"
      },
      "outputs": [],
      "source": [
        "train_image_paths, train_image_labels = read_data_from_folder(input_dir, 'train')\n",
        "val_image_paths, val_image_labels = read_data_from_folder(input_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1ciYbbe_oMQ",
        "outputId": "89d1ff78-8352-4374-e2d7-76fd42b6b9e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6000it [05:15, 19.02it/s]\n"
          ]
        }
      ],
      "source": [
        "train_features, train_labels = extract_feature(train_image_paths, train_image_labels, save_feature_path, image_processer)\n",
        "val_mega_data, val_labels = get_cat_dog_data(image_processer, save_codebook_path, val_image_paths, val_image_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Xây dựng từ điển trực quan**"
      ],
      "metadata": {
        "id": "sOXajVIoW_w4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PJhRJ8B_rWZ",
        "outputId": "baa430ca-861a-406d-f86c-cd7aeb65391c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6000/6000 [00:00<00:00, 337406.81it/s]\n"
          ]
        }
      ],
      "source": [
        "codebook = build_codebook(save_feature_path, save_codebook_path, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression Model**"
      ],
      "metadata": {
        "id": "MEkJC2KaXJ3E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpNQOJjHV9o8",
        "outputId": "1b19da54-b4d2-417e-bfa1-22e45e8f1430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6000it [45:34,  2.19it/s]\n",
            "2000it [20:31,  1.62it/s]\n"
          ]
        }
      ],
      "source": [
        "train_mega_data, train_labels = get_cat_dog_data(image_processer, save_codebook_path, train_image_paths, train_image_labels)\n",
        "val_mega_data, val_labels = get_cat_dog_data(image_processer, save_codebook_path, val_image_paths, val_image_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6SmuKQpZAUG",
        "outputId": "bd072011-c842-4a7d-c263-beedf333ef76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = LogisticRegression(random_state=0)\n",
        "clf.fit(np.squeeze(np.array(train_mega_data)), np.array(train_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Đánh giá mô hình**"
      ],
      "metadata": {
        "id": "p5Y_yq0fXjwz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjUZLi29ZCky",
        "outputId": "c9744d17-73bd-46ea-82ee-846dd879e0b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.67"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "#200\n",
        "pred = clf.predict(np.squeeze(np.array(val_mega_data)))\n",
        "accuracy_score(pred, np.array(val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tương tự với vocab_size=250, 300, ..., 500**"
      ],
      "metadata": {
        "id": "bcifliUaX_1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#500\n",
        "pred = clf.predict(np.squeeze(np.array(val_mega_data)))\n",
        "accuracy_score(pred, np.array(val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI4tVMAhe9PS",
        "outputId": "68c2ac34-a42d-4c61-a7ec-872de69a10ad"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.665"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#450\n",
        "pred = clf.predict(np.squeeze(np.array(val_mega_data)))\n",
        "accuracy_score(pred, np.array(val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cILLKhGGnFFI",
        "outputId": "d28f254d-12f6-4634-9053-85cbf509c56a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.667"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ4RznpDdnFd",
        "outputId": "0d29870a-7568-4ca3-9ea2-7043e95b3f90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6685"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#400\n",
        "pred = clf.predict(np.squeeze(np.array(val_mega_data)))\n",
        "accuracy_score(pred, np.array(val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#350\n",
        "pred = clf.predict(np.squeeze(np.array(val_mega_data)))\n",
        "accuracy_score(pred, np.array(val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVuCG3vprEEt",
        "outputId": "7881b469-3de1-4717-c4a0-2f1eb2f6b05a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.676"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TZXTSbGaQJp",
        "outputId": "b052b113-cf02-4b56-a6f0-9982962616a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6715"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#300\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "pred = clf.predict(np.squeeze(np.array(val_mega_data)))\n",
        "accuracy_score(pred, np.array(val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#250\n",
        "pred = clf.predict(np.squeeze(np.array(val_mega_data)))\n",
        "accuracy_score(pred, np.array(val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozhBVHjrzaJc",
        "outputId": "8cbb336f-d063-424b-b230-d5f00c8781ac"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.67"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}